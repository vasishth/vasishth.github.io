@comment{{This file has been generated by bib2bib 1.99}}

@comment{{Command line: bib2bib -ob vasishthunpub.bib -c 'author : "Vasishth"' -c '$type="UNPUBLISHED" or $type="unpublished"' bibcleaned.bib}}

@comment{{This file has been generated by bib2bib 1.74}}

@comment{{Command line: bib2bib /sw/share/texmf/bibtex/vasishth/bib/bibliography.bib}}

@unpublished{MertzenEtAl2021Glossa,
  author = {Mertzen, Daniela and Paape, Dario and Dillon, Brian W. and  Engbert, Ralf and Vasishth, Shravan},
  title = {Syntactic and semantic interference in sentence comprehension: {Support from English and German eye-tracking data}},
  year = {2021},
  note = {submitted},
  pdf = {https://psyarxiv.com/ua9yv}
}

@unpublished{Yadavetal2022,
  title = {Number feature distortion modulates cue-based retrieval in reading},
  author = {Himanshu Yadav and Garrett Smith and Sebastian Reich and Shravan Vasishth},
  year = {2022},
  optcode = {},
  pdf = {https://psyarxiv.com/s4c9t},
  note = {Submitted to the Journal of Memory and Language}
}

@unpublished{SmithVasishthOpenMind2021,
  title = {A software toolkit for modeling human sentence parsing: {A}n approach using continuous-time, discrete-state stochastic dynamical systems},
  author = {Garrett Smith and Shravan Vasishth},
  year = {2022},
  code = {https://anonymous.4open.science/r/fptools-6D7F/},
  pdf = {https://psyarxiv.com/dtazq/},
  note = {Submitted to Open Mind}
}

@unpublished{VasishthARL2022,
  author = {Shravan Vasishth},
  note = {Submitted},
  title = {Some right ways to analyze (psycho)linguistic data},
  year = {2022},
  doi = {10.17605/OSF.IO/5WZYG},
  pdf = {https://osf.io/u7ha4/},
  code = {https://osf.io/5wzyg/}
}

@comment{{BibDesk Smart Groups
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple Computer//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>conditions</key>
		<array>
			<dict>
				<key>comparison</key>
				<integer>2</integer>
				<key>key</key>
				<string>Vasishthpubs</string>
				<key>value</key>
				<string>vasishth</string>
				<key>version</key>
				<string>1</string>
			</dict>
		</array>
		<key>conjunction</key>
		<integer>0</integer>
		<key>group name</key>
		<string>vasishth</string>
	</dict>
</array>
</plist>
}}

@unpublished{PaapeVasishthBSPR2022,
  author = {Dario Paape and Shravan Vasishth},
  title = {When nothing goes right, go left: An investigation of revisionary and confirmatory rereading using bidirectional self-paced reading},
  year = {2022},
  note = {Submitted},
  optcode = {},
  optpdf = {}
}

@unpublished{PaapeVasishthMPT2022,
  author = {Dario Paape and Shravan Vasishth},
  title = {Estimating the true cost of garden-pathing: {A} computational model of latent cognitive processes},
  year = {2022},
  note = {Submitted},
  optcode = {},
  optpdf = {}
}

@unpublished{LissonEtAlInterference2021,
  author = {Paula Liss{\'o}n and Dario Paape and Dorothea Pregla and Frank Burchert and Nicole Stadie and Shravan Vasishth},
  title = {Similarity-based interference in sentence comprehension in aphasia: {A} computational evaluation of two models of cue-based retrieval},
  year = {2021},
  note = {submitted},
  pdf = {https://psyarxiv.com/jf65s}
}

@unpublished{PreglaTR,
  author = {Pregla, Dorothea and Liss{\'o}n, Paula and Vasishth, Shravan and Stadie, Nicole  and Burchert, Frank},
  note = {preprint},
  title = {Technical report: {Individual differences in visual world eye- tracking in aphasia in German}},
  url = {https://osf.io/bsnxu/?view_only=935420235a46439bb60cb574ecaaab66},
  year = {2020}
}

@unpublished{BatesEtAlParsimonious,
  author = {Bates, Douglas M. and Kliegl, Reinhold and Vasishth, Shravan and Baayen, Harald},
  note = {Unpublished manuscript},
  title = {Parsimonious mixed models},
  year = {2015},
  pdf = {http://arxiv.org/abs/1506.04967},
  abstract = {The analysis of experimental data with mixed-effects models requires
decisions about the specification of the appropriate random-effects structure.
Recently, Barr, et al 2013, recommended  fitting `maximal'
models with all possible random effect components included.  Estimation of
maximal models, however, may not converge.  We show that failure to converge
 typically is not due to a suboptimal estimation algorithm, but is
a consequence of attempting to fit a model that is too complex to be properly
supported by the data, irrespective of whether estimation is based on maximum
likelihood or on Bayesian hierarchical modeling with uninformative or weakly
informative priors.  Importantly, even under convergence, overparameterization
may lead to uninterpretable models.  We provide diagnostic tools for detecting
overparameterization and guiding model simplification.  Finally, we clarify
that the simulations on which Barr et al. base their recommendations are
atypical for real data.  A detailed example is provided of how subject-related
attentional fluctuation across trials may further qualify
statistical inferences about fixed effects, and of how such nonlinear effects
can be accommodated within the mixed-effects modeling framework.}
}

@unpublished{SchadEtAlAggregation2022,
  pdf = {https://arxiv.org/abs/2203.02361},
  author = {Schad, Daniel J. and Nicenboim, Bruno and Vasishth, Shravan},
  year = {2022},
  code = {https://osf.io/mjf47/},
  title = {Data aggregation can lead to biased inferences in {B}ayesian linear mixed models}
}

@unpublished{stone2022entropy,
  title = {Does entropy modulate the prediction of {G}erman long-distance verb particles?},
  author = {Stone, Kate and Vasishth, Shravan and von der Malsburg, Titus},
  year = {2022},
  optjournal = {PLoS ONE},
  pdf = {https://osf.io/7fb5t/},
  code = {https://osf.io/h75jm/}
}

@unpublished{MertzenEtAl2020,
  author = {Mertzen, Daniela and Laurinavichyute, Anna and Dillon, Brian W. and  Engbert, Ralf and Vasishth, Shravan},
  title = {Is there cross-linguistic evidence for proactive cue-based retrieval interference in sentence comprehension? {Eye-tracking data from English, German and Russian}},
  year = {2021},
  note = {submitted},
  url = {https://psyarxiv.com/t2j8v}
}

@unpublished{VasishthMixture2017,
  title = {Bayesian Hierarchical Finite Mixture Models of Reading Times: A Case Study},
  author = {Shravan Vasishth and Bruno Nicenboim and Nicolas Chopin and Robin Ryder},
  url = {https://arxiv.org/abs/1702.00564},
  abstract = {We present a case study demonstrating the importance of Bayesian hierarchical mixture models as a modelling tool for evaluating the predictions of competing theories of cognitive processes. As a case study, we revisit two published data sets from psycholinguistics.
In sentence comprehension, it is widely assumed that the distance between linguistic co-dependents affects the latency of dependency resolution: the longer the distance, the longer the time taken to complete the dependency (e.g., Gibson 2000). An alternative theory, direct access (McElree, 1993), assumes that retrieval times are a mixture of two distributions (Nicenboim & Vasishth, 2017): one distribution represents successful retrievals and the other represents an initial failure to retrieve the correct dependent, followed by a reanalysis that leads to successful retrieval. Here, dependency distance has the effect that in long-distance conditions the proportion of reanalyses is higher. We implement both theories as Bayesian hierarchical models and show that the direct-access model fits the Chinese relative clause reading time data better than the dependency-distance account.
This work makes several novel contributions.
First, we demonstrate how the researcher can reason about the underlying generative process of their data, thereby expressing the underlying cognitive process as a statistical model.
Second, we show how models that have been developed in an exploratory manner to represent different underlying generative processes can be compared in terms of their predictive performance, using both K-fold cross validation on existing data, and using completely new data. Finally, we show how the models can be evaluated using simulated data.},
  year = {2017},
  code = {http://www.ling.uni-potsdam.de/~vasishth/code/MixtureChinese.zip},
  note = {Unpublished MS},
  doi = {10.17605/OSF.IO/FWX3S}
}

@comment{{jabref-meta: databaseType:bibtex;}}

@comment{{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Markings\;2\;1\;\;\;\;;
2 StaticGroup:[malsburg]\;2\;1\;\;\;\;;
}}

